{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_transfer_learning_pub_km_class.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gskz7qXCpwCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Dec 31 12:55:35 2019\n",
        "\n",
        "@author: iab\n",
        "\"\"\"\n",
        "\n",
        "# import necessary packages\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import warnings\n",
        "import pickle\n",
        "import boto3\n",
        "import io\n",
        "\n",
        "# ignore warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class keymessage_affinityscore_model:\n",
        "    \n",
        "  ##########################################################################################################################################\n",
        "  # Learn the representation for sentences.\n",
        "  def pubsent_representation_labels(self, dfTextLabels):\n",
        "\n",
        "    try:\n",
        "\n",
        "      ############\n",
        "      # Load BERT models\n",
        "\n",
        "      # Load DistilBERT:\n",
        "      #model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "      # Load BERT\n",
        "      model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "      # Load pretrained model/tokenizer\n",
        "      tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "      model = model_class.from_pretrained(pretrained_weights)\n",
        "\n",
        "      df_1_text = df_1['Text']\n",
        "\n",
        "      # Tokenize\n",
        "      tokenized = df_1_text.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "\n",
        "      dftokenized = pd.DataFrame(tokenized)\n",
        "\n",
        "      # list of indexes which need to be dropped (rows with more than 145 tokens)\n",
        "      dropIndices = dftokenized.loc[dftokenized['Text'].map(len) > 145]\n",
        "\n",
        "      # drop tokens whose length is more than 145\n",
        "      dftokenized = dftokenized[dftokenized['Text'].map(len) < 145]\n",
        "\n",
        "      #dftokenized = dftokenized[dftokenized['Text'].map(len) != 148]\n",
        "      #dftokenized = dftokenized[dftokenized['Text'].map(len) != 328]\n",
        "      #dftokenized = dftokenized[dftokenized['Text'].map(len) != 338]\n",
        "\n",
        "      tokenized = dftokenized['Text']\n",
        "\n",
        "      max_len = 0\n",
        "      for i in tokenized.values:\n",
        "          if len(i) > max_len:\n",
        "              max_len = len(i)\n",
        "\n",
        "      padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
        "\n",
        "      #Masking\n",
        "      attention_mask = np.where(padded != 0, 1, 0)\n",
        "\n",
        "      input_ids = torch.tensor(padded)\n",
        "      attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
        "          \n",
        "      features = last_hidden_states[0][:,0,:].numpy()\n",
        "\n",
        "      dfLabels = dfTextLabels[['Brand Information','Comparative Info','Cost','Disease Management','Dosing & Administration','Efficacy','Indication','Pathology','Patient Profiles','Pharmacology','Physician Enablement','Risk Factors','Safety & Tolerability', 'Study Design', 'Summary', 'Unmet Needs', 'Anatomy', 'Physiology', 'Subjective Evidence', 'Novel Therapy', 'Counselling']]\n",
        "\n",
        "      # drop indices from dfLabels (those indices which were dropped in dfTokenized)\n",
        "      for i in dropIndices.index:\n",
        "        dfLabels.drop(i, inplace=True)\n",
        "\n",
        "      #dfLabels.drop(518, inplace=True)\n",
        "      #dfLabels.drop(520, inplace=True)\n",
        "      #dfLabels.drop(521, inplace=True)\n",
        "\n",
        "      return features, dfLabels\n",
        "\n",
        "    except Exception as e:\n",
        "      raise Exception('exception in pubsent_representation_labels() function: ' + str(e)) \n",
        "\n",
        "  ################################################################################################################\n",
        "  # fit the model to sentence representations\n",
        "  def fit(self, dfHCPTextLabels):\n",
        "\n",
        "    try:\n",
        "\n",
        "      features, dfLabels = self.pubsent_representation_labels(dfHCPTextLabels)\n",
        "\n",
        "      train_features, test_features, train_labels, test_labels = train_test_split(features, dfLabels)\n",
        "\n",
        "      ########### \n",
        "      key_message_list = ['Brand Information','Comparative Info','Cost','Disease Management','Dosing & Administration','Efficacy','Indication','Pathology','Patient Profiles','Pharmacology','Physician Enablement','Risk Factors','Safety & Tolerability', 'Study Design', 'Summary', 'Unmet Needs', 'Anatomy', 'Physiology', 'Subjective Evidence', 'Novel Therapy', 'Counselling']\n",
        "\n",
        "      abstract_score_overall_list = []\n",
        "\n",
        "      for i in range(train_labels.shape[0]):\n",
        "        abstract_score_list = []\n",
        "        for j in range(len(key_message_list)):\n",
        "          abstract_score_list.append(train_labels.iloc[i, j])\n",
        "        abstract_score_overall_list.append(abstract_score_list)\n",
        "      \n",
        "      key_message_mapping = []\n",
        "      for score_list in abstract_score_overall_list:\n",
        "            key_message_mapping.append(key_message_list[score_list.index(max(score_list))])\n",
        "            \n",
        "      df_labels_max = pd.DataFrame(key_message_mapping)\n",
        "\n",
        "      ###########\n",
        "      key_message_list = ['Brand Information','Comparative Info','Cost','Disease Management','Dosing & Administration','Efficacy','Indication','Pathology','Patient Profiles','Pharmacology','Physician Enablement','Risk Factors','Safety & Tolerability', 'Study Design', 'Summary', 'Unmet Needs', 'Anatomy', 'Physiology', 'Subjective Evidence', 'Novel Therapy', 'Counselling']\n",
        "\n",
        "      abstract_score_overall_list = []\n",
        "\n",
        "      for i in range(test_labels.shape[0]):\n",
        "        abstract_score_list = []\n",
        "        for j in range(len(key_message_list)):\n",
        "          abstract_score_list.append(test_labels.iloc[i, j])\n",
        "        abstract_score_overall_list.append(abstract_score_list)\n",
        "          \n",
        "      key_message_mapping = []\n",
        "      for score_list in abstract_score_overall_list:\n",
        "            key_message_mapping.append(key_message_list[score_list.index(max(score_list))])\n",
        "            \n",
        "      df_test_labels_max = pd.DataFrame(key_message_mapping)\n",
        "\n",
        "      ############    \n",
        "      # Create hyperparameter space\n",
        "\n",
        "      # create regularization penalty space\n",
        "      penalty = ['l1', 'l2']\n",
        "\n",
        "      # create regualrization hyperparameter space\n",
        "      C = np.logspace(0, 4, 10)\n",
        "\n",
        "      hyperparameters = dict(C=C, penalty=penalty)\n",
        "\n",
        "      lr_clf = LogisticRegression()\n",
        "\n",
        "      # Create grid search using 5-fold cross validation\n",
        "      clf = GridSearchCV(lr_clf, hyperparameters, cv=5, verbose=0)\n",
        "\n",
        "      # Fit grid search\n",
        "      best_model = clf.fit(train_features, df_labels_max)\n",
        "\n",
        "      #print('score: ', best_model.score(test_features, df_test_labels_max))\n",
        "      \n",
        "      return best_model\n",
        "\n",
        "    except Exception as e:\n",
        "      raise Exception('exception in model() function: ' + str(e)) \n",
        "\n",
        "  ####################################################################################################\n",
        "  # prepare the sentences_predicted_prob file from df_Prob as a df\n",
        "  def createAuthorAbstractProbabilties(self, dfHCPTextLabels, df_Prob):\n",
        "    \n",
        "    try:\n",
        "      \n",
        "        df_text_author = dfHCPTextLabels[['Text', 'author']]\n",
        "        df_text_author_prob = pd.concat([df_text_author, df_Prob], axis=1)\n",
        "        \n",
        "        return df_text_author_prob\n",
        "\n",
        "    except Exception as e:\n",
        "      raise Exception('exception in createAuthorAbstractNumProbabilties() function: ' + str(e)) \n",
        "\n",
        "\n",
        "  ####################################################################################################\n",
        "  def predict(self, features, dfLabels):\n",
        "\n",
        "    try:\n",
        "      \n",
        "      # make sentence score dataframe\n",
        "      lstProbabilities = list()\n",
        "      for feature in features:\n",
        "        lstProbabilities.append(model.predict_proba([feature]))\n",
        "\n",
        "      newlst = list()\n",
        "      for i in range(len(lstProbabilities)):\n",
        "        newlst.append(lstProbabilities[i][0])\n",
        "\n",
        "      dfSentencesProb = pd.DataFrame(newlst)\n",
        "      dfSentencesProb.columns = ['Brand_Information','Comparative_Info','Cost','Disease_Management','Dosing_&_Administration','Efficacy','Indication','Pathology','Patient_Profiles','Pharmacology','Physician_Enablement','Risk_Factors','Safety_&_Tolerability', 'Study_Design', 'Unmet_Needs', 'Anatomy', 'Physiology', 'Subjective_Evidence', 'Novel_Therapy', 'Counselling']\n",
        " \n",
        "      return dfSentencesProb\n",
        "\n",
        "    except Exception as e:\n",
        "      raise Exception('exception in predict() function: ' + str(e))\n",
        "\n",
        "  #####################################################################################################\n",
        "  def predict_sentence_level(self, dfHCPTextLabels):\n",
        "\n",
        "    try:\n",
        "      \n",
        "      features, dfLabels = self.pubsent_representation_labels(dfHCPTextLabels)\n",
        "      dfProb = self.predict(features, dfLabels)\n",
        "      \n",
        "      #########\n",
        "      # aggregating at the author level\n",
        "      \n",
        "      dfSentencesProb = self.createAuthorAbstractProbabilties(dfHCPTextLabels, dfProb)\n",
        "            \n",
        "      return dfSentencesProb\n",
        "\n",
        "    except Exception as e:\n",
        "      raise Exception('exception in predict_sentence_level() function: ' + str(e)) \n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}