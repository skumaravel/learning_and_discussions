{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_transfer_learning_pub_km_class.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gskz7qXCpwCT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "e4f57f7b-252c-449f-c947-ca1c39b9d6a8"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Dec 31 12:55:35 2019\n",
        "\n",
        "@author: iab\n",
        "\"\"\"\n",
        "\n",
        "# import necessary packages\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import warnings\n",
        "import pickle\n",
        "import boto3\n",
        "import io\n",
        "\n",
        "# ignore warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class keymessage_affinityscore_model:\n",
        "    \n",
        "  ##########################################################################################################################################\n",
        "  # Learn the representation for sentences.\n",
        "  def pubsent_representation_labels(self, dfTextLabels):\n",
        "\n",
        "    try:\n",
        "\n",
        "      ############\n",
        "      # Load BERT models\n",
        "\n",
        "      # Load DistilBERT:\n",
        "      #model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "      # Load BERT\n",
        "      model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "      # Load pretrained model/tokenizer\n",
        "      tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "      model = model_class.from_pretrained(pretrained_weights)\n",
        "\n",
        "      df_1_text = dfTextLabels['Text']\n",
        "\n",
        "      # Tokenize\n",
        "      tokenized = df_1_text.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "\n",
        "      dftokenized = pd.DataFrame(tokenized)\n",
        "\n",
        "      # list of indexes (from labels column) which need to be dropped (rows with more than 145 tokens)\n",
        "      dropIndices = dftokenized.loc[dftokenized['Text'].map(len) > 145]\n",
        "\n",
        "      # drop tokens whose length is more than 145\n",
        "      dftokenized = dftokenized[dftokenized['Text'].map(len) < 145]\n",
        "\n",
        "      #dftokenized = dftokenized[dftokenized['Text'].map(len) != 148]\n",
        "      #dftokenized = dftokenized[dftokenized['Text'].map(len) != 328]\n",
        "      #dftokenized = dftokenized[dftokenized['Text'].map(len) != 338]\n",
        "\n",
        "      tokenized = dftokenized['Text']\n",
        "\n",
        "      max_len = 0\n",
        "      for i in tokenized.values:\n",
        "          if len(i) > max_len:\n",
        "              max_len = len(i)\n",
        "\n",
        "      padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
        "\n",
        "      #Masking\n",
        "      attention_mask = np.where(padded != 0, 1, 0)\n",
        "\n",
        "      input_ids = torch.tensor(padded)\n",
        "      attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
        "          \n",
        "      features = last_hidden_states[0][:,0,:].numpy()\n",
        "\n",
        "      dfLabels = dfTextLabels[['Brand Information','Comparative Info','Cost','Disease Management','Dosing & Administration','Efficacy','Indication','Pathology','Patient Profiles','Pharmacology','Physician Enablement','Risk Factors','Safety & Tolerability', 'Study Design', 'Unmet Needs', 'Anatomy', 'Physiology', 'Subjective Evidence', 'Novel Therapy', 'Counselling']]\n",
        "\n",
        "      # drop indices from dfLabels (those indices which were dropped in dfTokenized)\n",
        "      for i in dropIndices.index:\n",
        "        dfLabels.drop(i, inplace=True)\n",
        "\n",
        "      #dfLabels.drop(518, inplace=True)\n",
        "      #dfLabels.drop(520, inplace=True)\n",
        "      #dfLabels.drop(521, inplace=True)\n",
        "\n",
        "      return features, dfLabels\n",
        "\n",
        "    except Exception as e:\n",
        "      raise Exception('exception in pubsent_representation_labels() function: ' + str(e)) \n",
        "\n",
        "  ################################################################################################################\n",
        "  # fit the model to sentence representations\n",
        "  def fit(self, dfHCPTextLabels):\n",
        "\n",
        "    try:\n",
        "\n",
        "      features, dfLabels = self.pubsent_representation_labels(dfHCPTextLabels)\n",
        "\n",
        "      train_features, test_features, train_labels, test_labels = train_test_split(features, dfLabels)\n",
        "\n",
        "      ########### \n",
        "      key_message_list = ['Brand Information','Comparative Info','Cost','Disease Management','Dosing & Administration','Efficacy','Indication','Pathology','Patient Profiles','Pharmacology','Physician Enablement','Risk Factors','Safety & Tolerability', 'Study Design', 'Summary', 'Unmet Needs', 'Anatomy', 'Physiology', 'Subjective Evidence', 'Novel Therapy', 'Counselling']\n",
        "\n",
        "      abstract_score_overall_list = []\n",
        "\n",
        "      for i in range(train_labels.shape[0]):\n",
        "        abstract_score_list = []\n",
        "        for j in range(len(key_message_list)):\n",
        "          abstract_score_list.append(train_labels.iloc[i, j])\n",
        "        abstract_score_overall_list.append(abstract_score_list)\n",
        "      \n",
        "      key_message_mapping = []\n",
        "      for score_list in abstract_score_overall_list:\n",
        "            key_message_mapping.append(key_message_list[score_list.index(max(score_list))])\n",
        "            \n",
        "      df_labels_max = pd.DataFrame(key_message_mapping)\n",
        "\n",
        "      ###########\n",
        "      key_message_list = ['Brand Information','Comparative Info','Cost','Disease Management','Dosing & Administration','Efficacy','Indication','Pathology','Patient Profiles','Pharmacology','Physician Enablement','Risk Factors','Safety & Tolerability', 'Study Design', 'Unmet Needs', 'Anatomy', 'Physiology', 'Subjective Evidence', 'Novel Therapy', 'Counselling']\n",
        "\n",
        "      abstract_score_overall_list = []\n",
        "\n",
        "      for i in range(test_labels.shape[0]):\n",
        "        abstract_score_list = []\n",
        "        for j in range(len(key_message_list)):\n",
        "          abstract_score_list.append(test_labels.iloc[i, j])\n",
        "        abstract_score_overall_list.append(abstract_score_list)\n",
        "          \n",
        "      key_message_mapping = []\n",
        "      for score_list in abstract_score_overall_list:\n",
        "            key_message_mapping.append(key_message_list[score_list.index(max(score_list))])\n",
        "            \n",
        "      df_test_labels_max = pd.DataFrame(key_message_mapping)\n",
        "\n",
        "      ############    \n",
        "      # Create hyperparameter space\n",
        "\n",
        "      # create regularization penalty space\n",
        "      penalty = ['l1', 'l2']\n",
        "\n",
        "      # create regualrization hyperparameter space\n",
        "      C = np.logspace(0, 4, 10)\n",
        "\n",
        "      hyperparameters = dict(C=C, penalty=penalty)\n",
        "\n",
        "      lr_clf = LogisticRegression()\n",
        "\n",
        "      # Create grid search using 5-fold cross validation\n",
        "      clf = GridSearchCV(lr_clf, hyperparameters, cv=5, verbose=0)\n",
        "\n",
        "      # Fit grid search\n",
        "      best_model = clf.fit(train_features, df_labels_max)\n",
        "\n",
        "      #print('score: ', best_model.score(test_features, df_test_labels_max))\n",
        "      \n",
        "      return best_model\n",
        "\n",
        "    except Exception as e:\n",
        "      raise Exception('exception in model() function: ' + str(e)) \n",
        "\n",
        "  ####################################################################################################\n",
        "  # prepare the sentences_predicted_prob file from df_Prob as a df\n",
        "  def createAuthorAbstractProbabilties(self, dfHCPTextLabels, df_Prob):\n",
        "    \n",
        "    try:\n",
        "      \n",
        "        df_text_author = dfHCPTextLabels[['Text', 'author']]\n",
        "        df_text_author_prob = pd.concat([df_text_author, df_Prob], axis=1)\n",
        "        \n",
        "        return df_text_author_prob\n",
        "\n",
        "    except Exception as e:\n",
        "      raise Exception('exception in createAuthorAbstractNumProbabilties() function: ' + str(e)) \n",
        "\n",
        "\n",
        "  ####################################################################################################\n",
        "  def predict(self, features, dfLabels):\n",
        "\n",
        "    try:\n",
        "      \n",
        "      # make sentence score dataframe\n",
        "      lstProbabilities = list()\n",
        "      for feature in features:\n",
        "        lstProbabilities.append(model.predict_proba([feature]))\n",
        "\n",
        "      newlst = list()\n",
        "      for i in range(len(lstProbabilities)):\n",
        "        newlst.append(lstProbabilities[i][0])\n",
        "\n",
        "      dfSentencesProb = pd.DataFrame(newlst)\n",
        "      dfSentencesProb.columns = ['Brand_Information','Comparative_Info','Cost','Disease_Management','Dosing_&_Administration','Efficacy','Indication','Pathology','Patient_Profiles','Pharmacology','Physician_Enablement','Risk_Factors','Safety_&_Tolerability', 'Study_Design', 'Unmet_Needs', 'Anatomy', 'Physiology', 'Subjective_Evidence', 'Novel_Therapy', 'Counselling']\n",
        " \n",
        "      return dfSentencesProb\n",
        "\n",
        "    except Exception as e:\n",
        "      raise Exception('exception in predict() function: ' + str(e))\n",
        "\n",
        "  #####################################################################################################\n",
        "  def predict_sentence_level(self, dfHCPTextLabels):\n",
        "\n",
        "    try:\n",
        "      \n",
        "      features, dfLabels = self.pubsent_representation_labels(dfHCPTextLabels)\n",
        "      dfProb = self.predict(features, dfLabels)\n",
        "      \n",
        "      #########\n",
        "      # aggregating at the author level\n",
        "      \n",
        "      dfSentencesProb = self.createAuthorAbstractProbabilties(dfHCPTextLabels, dfProb)\n",
        "            \n",
        "      return dfSentencesProb\n",
        "\n",
        "    except Exception as e:\n",
        "      raise Exception('exception in predict_sentence_level() function: ' + str(e)) \n",
        "\n",
        "  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xe3epk3EOBw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "3e8d77e8-8c07-4f30-a987-0a91bd102bcc"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsKEL00GEkCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "dfTextLabels = pd.read_excel('sentences_scores.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CehemjdjLGZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfTextLabels.drop(['Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcxf8-IVEEkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cls = keymessage_affinityscore_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwBV0ROyKiRn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "2fa3610f-05b1-4d45-a5a7-a9429ed30b1a"
      },
      "source": [
        "dfTextLabels.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Brand Information</th>\n",
              "      <th>Comparative Info</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Disease Management</th>\n",
              "      <th>Dosing &amp; Administration</th>\n",
              "      <th>Efficacy</th>\n",
              "      <th>Indication</th>\n",
              "      <th>Pathology</th>\n",
              "      <th>Patient Profiles</th>\n",
              "      <th>Pharmacology</th>\n",
              "      <th>Physician Enablement</th>\n",
              "      <th>Risk Factors</th>\n",
              "      <th>Safety &amp; Tolerability</th>\n",
              "      <th>Study Design</th>\n",
              "      <th>Unmet Needs</th>\n",
              "      <th>Anatomy</th>\n",
              "      <th>Physiology</th>\n",
              "      <th>Subjective Evidence</th>\n",
              "      <th>Novel Therapy</th>\n",
              "      <th>Counselling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE: To determine if clinically used bot...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DESIGN: Prospective study.</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SETTING: Academic medical center in St Louis, Mo.</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SUBJECTS: Twenty-nine adult patients treated w...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>INTERVENTION: The eyebrow position at 13 diffe...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...  Counselling\n",
              "0  OBJECTIVE: To determine if clinically used bot...  ...          0.0\n",
              "1                         DESIGN: Prospective study.  ...          0.0\n",
              "2  SETTING: Academic medical center in St Louis, Mo.  ...          0.0\n",
              "3  SUBJECTS: Twenty-nine adult patients treated w...  ...          0.0\n",
              "4  INTERVENTION: The eyebrow position at 13 diffe...  ...          0.0\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_CDos6aEzHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = cls.pubsent_representation_labels(dfTextLabels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XIeAkATUGk7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb753941-1679-41f1-9f1b-f6250cc0018c"
      },
      "source": [
        "len(model[0][0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}